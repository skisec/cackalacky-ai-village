{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ZxcRyr3Xl4"
      },
      "source": [
        "# Fine Tine ModernBERT\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g22xJSM7v6BvrD9F.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"200\"/>\n",
        "\n",
        "[Publication](https://arxiv.org/pdf/2412.13663)\n",
        "\n",
        "## What is ModernBERT?\n",
        "\n",
        "- Latest encoding family model\n",
        "  - Trained with 2T tokens\n",
        "  - 8192 sequence length\n",
        "- Better, faster, smarter\n",
        "  - Major pareto improvement\n",
        "\n",
        "\n",
        "## What are the BERT family models?\n",
        "- Encoder only\n",
        "- Representing text\n",
        "- Classifying text\n",
        "- Meaningful embeddings\n",
        "\n",
        "## Why should you care?\n",
        "- Specialized semantic representation for security terms\n",
        "- Classification of malicious vs benign"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3xiDQyv9FrF"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kNHCgBgRiqwd",
        "outputId": "82c982ea-e409-4705-b374-974da95f0d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==2.5.0 in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "Requirement already satisfied: torchvision==0.20.0 in /usr/local/lib/python3.11/dist-packages (0.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.0) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0) (3.0.2)\n",
            "Requirement already satisfied: setuptools<71.0.0 in /usr/local/lib/python3.11/dist-packages (70.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: datasets==3.1.0 in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: accelerate==1.2.1 in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: hf-transfer==0.1.8 in /usr/local/lib/python3.11/dist-packages (0.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.1.0) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0) (6.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.2.1) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.2.1) (2.5.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.2.1) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets==3.1.0) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.1.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.1.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.1.0) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.2.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==1.2.1) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.1.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.1.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==1.2.1) (3.0.2)\n",
            "Collecting git+https://github.com/huggingface/transformers.git@6e0515e99c39444caae39472ee1b2fd76ece32f1\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision 6e0515e99c39444caae39472ee1b2fd76ece32f1) to /tmp/pip-req-build-ogiehwad\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-ogiehwad\n",
            "  Running command git rev-parse -q --verify 'sha^6e0515e99c39444caae39472ee1b2fd76ece32f1'\n",
            "  Running command git fetch -q https://github.com/huggingface/transformers.git 6e0515e99c39444caae39472ee1b2fd76ece32f1\n",
            "  Running command git checkout -q 6e0515e99c39444caae39472ee1b2fd76ece32f1\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 6e0515e99c39444caae39472ee1b2fd76ece32f1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.0.dev0) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.0.dev0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.0.dev0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.0.dev0) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "# Install Pytorch & other libraries\n",
        "%pip install \"torch==2.5.0\" \"torchvision==0.20.0\"\n",
        "%pip install \"setuptools<71.0.0\" scikit-learn\n",
        "%pip install python-dotenv\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "%pip install  --upgrade \\\n",
        "  \"datasets==3.1.0\" \\\n",
        "  \"accelerate==1.2.1\" \\\n",
        "  \"hf-transfer==0.1.8\"\n",
        "\n",
        "# ModernBERT is not yet available in an official release, so we need to install it from github\n",
        "%pip install \"git+https://github.com/huggingface/transformers.git@6e0515e99c39444caae39472ee1b2fd76ece32f1\" --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WLHtcToduTgx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from datasets import load_dataset\n",
        "from datasets.arrow_dataset import Dataset\n",
        "from datasets.dataset_dict import DatasetDict, IterableDatasetDict\n",
        "from datasets.iterable_dataset import IterableDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Vmt9pAqz2-8i"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "hugging_face_key = userdata.get('HUGGING_FACE_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L3sU_du2ubXo"
      },
      "outputs": [],
      "source": [
        "# login to hugging face\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(token=hugging_face_key, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDfd3YrTJWlR",
        "outputId": "fc12ccb8-13ab-4dd0-d4a1-bbf4c6b9425e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# check GPU\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbCeQx-I9J1D"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KGK3ocNEbA1"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "faf1de246d02443184d9d715aa215aa8",
            "f922113cc91040a486bc3a5c34930d06",
            "065e67c9ee5347dba2900f7ea89f96e7"
          ]
        },
        "id": "5qSVtW_kOLme",
        "outputId": "0ba73e6f-ecca-4857-9e43-27fa15e26b80"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Define your list of strings\n",
        "list_dataset_ids = ['ealvaradob/phishing-dataset', 'Anvilogic/URL-Guardian-Dataset', 'tegridydev/open-malsec']\n",
        "\n",
        "# Create the dropdown widget\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=list_dataset_ids,\n",
        "    description='Select an dataset:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Display the dropdown\n",
        "display(dropdown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a1gy__ghWDwd"
      },
      "outputs": [],
      "source": [
        "dataset_id = dropdown.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbtXqefIG3uw",
        "outputId": "b8643729-f430-41ab-f30c-940d91bbe159"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'double-glazing-leeds.org.uk', 'label': 1}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load raw dataset, adding trust_remote_code=True\n",
        "train_dataset = load_dataset(dataset_id, split=\"train\", trust_remote_code=True)\n",
        "\n",
        "split_dataset = train_dataset.train_test_split(test_size=0.1)\n",
        "split_dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "a635lyrNvPmx"
      },
      "outputs": [],
      "source": [
        "# reduce dataset size to half\n",
        "import datasets\n",
        "\n",
        "reduced_dataset = datasets.DatasetDict({\n",
        "    'train': split_dataset['train'].select(range(split_dataset['train'].num_rows // 2)),\n",
        "    'test': split_dataset['test'].select(range(split_dataset['test'].num_rows // 2))\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDXDkKlAEf7t"
      },
      "source": [
        "## Tokenize\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mkvzSPMiX5FZcuQjFe2B6w.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"500\"/>\n",
        "\n",
        "(image from [The Art of Tokenization: Breaking Down Text for AI](https://medium.com/data-science/the-art-of-tokenization-breaking-down-text-for-ai-43c7bccaed25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VQ9bpNztX7_z"
      },
      "outputs": [],
      "source": [
        "# Model id to load the tokenizer\n",
        "model_id = \"answerdotai/ModernBERT-base\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "4934eb939fa743ab8ef30bd54ee9b576",
            "cb3dd94bae94479ea4ccaa5499876f98",
            "a19fe02029ff4ebf822ee65754c73b68",
            "0f4ddf4f7898453bb8b52d744c226fd2",
            "f0ffeba87a8c41f6bf98af6b23ed0f26",
            "f9b85807705344bea59c9ed1cd80f72d",
            "73153284796a40e78ceef9e587c33e3c",
            "637b25cb9f0f42dead34f2575a239234",
            "51a746635f5145ce8b36db875d5c6a6a",
            "d8e4e9069dd74a40901a83849040ef89",
            "aa86f66883a24346a064264d36267e73",
            "0cac8cdbcae24d18b211dcaece92c116",
            "c929cebb52d14712ad0d5aab2b45f058",
            "e19d971681f14ae591afd6c968ea3279",
            "378a49a025874efbae6c83419e94ab64",
            "10739c534895447493a638ff1697e147",
            "ba63ab1428f540d5875782db5d0305ce",
            "821096e6d7e445cdaed5883bb74c73f5",
            "80cc0e52e1bd4f3fbbc2b7b816563905",
            "89a36c88e9e9478da99498210f4cebdf",
            "0086db6737a2441c9228c09f79e48671",
            "7085e26dee43448fa9c47e08da13a482"
          ]
        },
        "id": "QCOXtmDXvSTD",
        "outputId": "96ee73ce-87ce-49d8-f451-895b3b13a4c7"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "\n",
        "# Tokenize helper function\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "# Tokenize dataset\n",
        "# Note: here we can use reduced_dataset OR split_dataset\n",
        "if \"label\" in reduced_dataset[\"train\"].features.keys():\n",
        "    reduced_dataset = reduced_dataset.rename_column(\"label\", \"labels\")  # to match Trainer\n",
        "tokenized_dataset = reduced_dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "tokenized_dataset[\"train\"].features.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d46d0acd33cc47988be2e7efac92e1e5",
            "81da6ec14aee45d887cb4069debea1c9",
            "9743883662e8407e98707c8745b5c2be",
            "b93ed23fb0784c3b9de1e52ded4903c3",
            "00d7b34aa6334c81baee4f7a404f7124",
            "809a3f0c8543497bb0d6120e5f92821e",
            "cb8cd7d6971e42bfb22d73ec148d3094",
            "cd34641d570d4030a6b6449a7c12d92d",
            "9ab224c133344b2daa1e7dd75c8bbad7",
            "7adbbff96423423597695399e76c5d0f",
            "aa11d2d1c0154122a40dac337ada121c",
            "1296b942c28e4967b26b23140e13617f",
            "6947b89b8e78462692f92ad573abcd1c",
            "2c9ebd6a56494984aab775a83c465277",
            "f232adb44ae746d3b294b6574caa317c",
            "cacc4d3ac53442c589df6f882bac2fe6",
            "a0dfa10a3d434eb6a5445887d47cdb30",
            "c0dded3772a748ef8aff7a93e147e9d4",
            "f826e5f49a6944cdb4dca7ee738d2bb4",
            "5e6ddc767b6a4a9e97b11f1b309a1118",
            "ce4a74314efd4e69a4428e50d192315d",
            "db16cb01bd1f42ce845e8df67e10f110"
          ]
        },
        "id": "ZtpemiS4JAYy",
        "outputId": "97090ff6-5612-421c-b581-cb98cb7e3d93"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "\n",
        "# Save the tokenized dataset to disk\n",
        "tokenized_dataset.save_to_disk('tokenized_dataset_reduced')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VFz3B3UiJE4b"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = datasets.load_from_disk('tokenized_dataset_reduced')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpfUZf0YEjg3"
      },
      "source": [
        "## Process labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMLotGb17m-B",
        "outputId": "3440c732-c2c9-47af-944f-1355a9e6c3dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': ['labels', 'input_ids', 'attention_mask'],\n",
              " 'test': ['labels', 'input_ids', 'attention_mask']}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset.column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcxslXmTvWoY",
        "outputId": "f81a8458-a14d-4e7f-b2ef-70cdc8346c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 13.2 ms, sys: 2 µs, total: 13.2 ms\n",
            "Wall time: 13 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Prepare model labels - useful for inference\n",
        "labels = tokenized_dataset[\"train\"].unique(\"labels\")\n",
        "num_labels = len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHGZ1Eh7qrrA",
        "outputId": "f1963094-d07a-461f-ab25-5a4f19d378be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.07 s, sys: 103 ms, total: 1.18 s\n",
            "Wall time: 1.46 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "label2id, id2label = dict(), dict()\n",
        "# for i, label in enumerate(labels):\n",
        "#     label2id[label] = str(i)\n",
        "#     id2label[str(i)] = label\n",
        "\n",
        "label2id['benign'] = 0\n",
        "label2id['malicious'] = 1\n",
        "id2label[0] = 'benign'\n",
        "id2label[1] = 'malicious'\n",
        "\n",
        "# Download the model from huggingface.co/models\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaB6ACw_pLE1",
        "outputId": "71eec091-3fb8-4964-9835-fadbe7ab93b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:167: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4.33 s, sys: 520 ms, total: 4.85 s\n",
            "Wall time: 5.61 s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'label': 'malicious', 'score': 0.6254871487617493}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "# show original model estimate\n",
        "from transformers import pipeline\n",
        "\n",
        "# load model from huggingface.co/models using our repository id\n",
        "classifier = pipeline(\n",
        "    task=\"text-classification\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0,\n",
        ")\n",
        "\n",
        "sample = split_dataset[\"test\"][42]['text']\n",
        "\n",
        "# Get the model's configuration\n",
        "config = classifier.model.config\n",
        "\n",
        "# Check if the key 0 exists in id2label, if not, add it with a default label\n",
        "if 0 not in config.id2label:\n",
        "    # Choose a suitable default label\n",
        "    default_label = \"unknown\"\n",
        "    config.id2label[0] = default_label\n",
        "    config.label2id[default_label] = 0\n",
        "\n",
        "classifier(sample)\n",
        "# [{'label': 'health', 'score': 0.6779336333274841}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBp7NsoSEm5q"
      },
      "source": [
        "## Evaluate\n",
        "<img src=\"https://sharpsight.ai/wp-content/uploads/2023/11/f1-score_simple-explanation.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"600\"/>\n",
        "\n",
        "**Precision**:\n",
        "\n",
        "Measures the accuracy of positive predictions. It's the ratio of correctly identified positive cases to all cases predicted as positive.\n",
        "\n",
        "**Recall**:\n",
        "\n",
        "Measures the ability to find all relevant positive cases. It's the ratio of correctly identified positive cases to all actual positive cases.\n",
        "\n",
        "**F1 Score**:\n",
        "\n",
        "The harmonic mean of precision and recall. It gives more weight to the lower value, emphasizing a balance between precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_niu9MWqvxuu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "# Metric helper method\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    score = f1_score(\n",
        "        labels, predictions, labels=labels, pos_label=1, average=\"weighted\"\n",
        "    )\n",
        "    return {\"f1\": float(score) if score == 1 else score}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUgvFkY7EpOX"
      },
      "source": [
        "## Fine Tuning\n",
        "\n",
        "Fine-tuning means adjusting the weights of a pre-trained model on a new dataset for better performance and specialization in a specific task.\n",
        "\n",
        "<img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52844fcc-6094-4fdb-ba8c-52737ab9c821_1640x402.gif\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"800\"/>\n",
        "\n",
        "(image from [Daily Dose of Data Science](https://blog.dailydoseofds.com/p/full-model-fine-tuning-vs-lora-vs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "Ka4OoZERvz54",
        "outputId": "74ddf594-fe2f-42a5-8113-59fe3076230c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13110' max='13110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13110/13110 27:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.170700</td>\n",
              "      <td>0.153612</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.087700</td>\n",
              "      <td>0.152765</td>\n",
              "      <td>0.968118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.018200</td>\n",
              "      <td>0.181089</td>\n",
              "      <td>0.969383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 33min 38s, sys: 55 s, total: 34min 33s\n",
            "Wall time: 27min 57s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=13110, training_loss=0.06990699079544813, metrics={'train_runtime': 1676.8684, 'train_samples_per_second': 62.534, 'train_steps_per_second': 7.818, 'total_flos': 1.7866274624464896e+16, 'train_loss': 0.06990699079544813, 'epoch': 3.0})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "# TODO: figure out why loss nan and no improvement in F1\n",
        "import torch\n",
        "from huggingface_hub import HfFolder\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Define training args\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./ModernBERT-domain-classifier\",\n",
        "#     per_device_train_batch_size=8,  # Reduced to 8\n",
        "#     per_device_eval_batch_size=4,  # Reduced to 4\n",
        "#     learning_rate=5e-5,\n",
        "#     num_train_epochs=3,\n",
        "#     fp16=True,\n",
        "#     optim=\"adamw_torch_fused\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "#     save_strategy=\"epoch\",\n",
        "#     save_total_limit=2,\n",
        "#     load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "#     push_to_hub=True,\n",
        "#     hub_strategy=\"every_save\",\n",
        "#     hub_token=hugging_face_key,\n",
        "#     gradient_checkpointing=True,\n",
        "#     gradient_accumulation_steps=1, # Reduced to 1\n",
        ")\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K-je3IuErpk"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og7xdhslFRa2",
        "outputId": "b92195f8-08a5-4369-cc5b-cc3d8ca25efc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./fine_tuned_model/tokenizer_config.json',\n",
              " './fine_tuned_model/special_tokens_map.json',\n",
              " './fine_tuned_model/tokenizer.json')"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the model\n",
        "model.save_pretrained(\"./fine_tuned_model\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FxzUvcUKQ5rJ",
        "outputId": "834f93ce-1fb0-4390-cfe0-bdff99a3e242"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'http : / / hrweb . enron . com / benefits / formp . asp'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_dataset[\"test\"][42]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyXXT6gfv4z4",
        "outputId": "40880c7b-d664-4de6-8797-02832a3c7cda"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 30.5 ms, sys: 12 µs, total: 30.5 ms\n",
            "Wall time: 30.2 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'label': 'malicious', 'score': 0.9883324503898621}]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "from transformers import pipeline\n",
        "\n",
        "# load model from huggingface.co/models using our repository id\n",
        "classifier = pipeline(\n",
        "    task=\"text-classification\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0,\n",
        ")\n",
        "\n",
        "sample = split_dataset[\"test\"][42]['text']\n",
        "\n",
        "# Get the model's configuration\n",
        "config = classifier.model.config\n",
        "\n",
        "# Check if the key 0 exists in id2label, if not, add it with a default label\n",
        "if 0 not in config.id2label:\n",
        "    # Choose a suitable default label\n",
        "    default_label = \"unknown\"\n",
        "    config.id2label[0] = default_label\n",
        "    config.label2id[default_label] = 0\n",
        "\n",
        "classifier(sample)\n",
        "# [{'label': 'health', 'score': 0.6779336333274841}]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
