{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ZxcRyr3Xl4"
      },
      "source": [
        "# Fine Tine ModernBERT\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g22xJSM7v6BvrD9F.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"200\"/>\n",
        "\n",
        "[Publication](https://arxiv.org/pdf/2412.13663)\n",
        "\n",
        "## What is ModernBERT?\n",
        "\n",
        "- Latest encoding family model\n",
        "  - Trained with 2T tokens\n",
        "  - 8192 sequence length\n",
        "- Better, faster, smarter\n",
        "  - Major pareto improvement\n",
        "\n",
        "\n",
        "## What are the BERT family models?\n",
        "- Encoder only\n",
        "- Representing text\n",
        "- Classifying text\n",
        "- Meaningful embeddings\n",
        "\n",
        "## Why should you care?\n",
        "- Specialized semantic representation for security terms\n",
        "- Classification of malicious vs benign"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kNHCgBgRiqwd",
        "outputId": "fbdbf585-d114-4c1d-e6e1-6a0a1c9fbcf9"
      },
      "outputs": [],
      "source": [
        "# Install Pytorch & other libraries\n",
        "%pip install \"torch==2.5.0\" \"torchvision==0.20.0\"\n",
        "%pip install \"setuptools<71.0.0\" scikit-learn\n",
        "%pip install python-dotenv\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "%pip install  --upgrade \\\n",
        "  \"datasets==3.1.0\" \\\n",
        "  \"accelerate==1.2.1\" \\\n",
        "  \"hf-transfer==0.1.8\"\n",
        "\n",
        "# ModernBERT is not yet available in an official release, so we need to install it from github\n",
        "%pip install \"git+https://github.com/huggingface/transformers.git@6e0515e99c39444caae39472ee1b2fd76ece32f1\" --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLHtcToduTgx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from datasets import load_dataset\n",
        "from datasets.arrow_dataset import Dataset\n",
        "from datasets.dataset_dict import DatasetDict, IterableDatasetDict\n",
        "from datasets.iterable_dataset import IterableDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vmt9pAqz2-8i"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "hugging_face_key = userdata.get('HUGGING_FACE_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3sU_du2ubXo"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token=hugging_face_key, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDfd3YrTJWlR",
        "outputId": "e7fa30f7-e1a2-4050-9e0c-f32d05089e41"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KGK3ocNEbA1"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b2d79d7a3fda415c950ede99efc97e57",
            "edf8f1dd41e2453f8ba3b449bbcd3956",
            "9a77fd9beb854350b94e1a100129691c"
          ]
        },
        "id": "5qSVtW_kOLme",
        "outputId": "4774bab6-7cd8-4bf7-f484-8aa39e60f3c5"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Define your list of strings\n",
        "list_dataset_ids = ['ealvaradob/phishing-dataset', 'Anvilogic/URL-Guardian-Dataset', 'tegridydev/open-malsec']\n",
        "\n",
        "# Create the dropdown widget\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=list_dataset_ids,\n",
        "    description='Select an dataset:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Display the dropdown\n",
        "display(dropdown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1gy__ghWDwd"
      },
      "outputs": [],
      "source": [
        "dataset_id = dropdown.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbtXqefIG3uw"
      },
      "outputs": [],
      "source": [
        "# Load raw dataset, adding trust_remote_code=True\n",
        "train_dataset = load_dataset(dataset_id, split=\"train\", trust_remote_code=True)\n",
        "\n",
        "split_dataset = train_dataset.train_test_split(test_size=0.1)\n",
        "split_dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "y5z_pKKImZ6B"
      },
      "outputs": [],
      "source": [
        "for item in split_dataset[\"train\"].select(range(0, 1000)):\n",
        "  print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a635lyrNvPmx"
      },
      "outputs": [],
      "source": [
        "# reduce dataset size to half\n",
        "import datasets\n",
        "\n",
        "reduced_dataset = datasets.DatasetDict({\n",
        "    'train': split_dataset['train'].select(range(split_dataset['train'].num_rows // 2)),\n",
        "    'test': split_dataset['test'].select(range(split_dataset['test'].num_rows // 2))\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDXDkKlAEf7t"
      },
      "source": [
        "## Tokenize\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mkvzSPMiX5FZcuQjFe2B6w.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"500\"/>\n",
        "\n",
        "(image from [The Art of Tokenization: Breaking Down Text for AI](https://medium.com/data-science/the-art-of-tokenization-breaking-down-text-for-ai-43c7bccaed25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ9bpNztX7_z"
      },
      "outputs": [],
      "source": [
        "# Model id to load the tokenizer\n",
        "model_id = \"answerdotai/ModernBERT-base\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "6e658f965c84401daefd30c007255f65",
            "12cd49aefb0d4a11aa5b66897f4090d1",
            "62b9081dc4c9490082cb49734494968e",
            "59fa67f16ea84428a2a2dce803b2d690",
            "9e3cd36f39684ee7bebfa02ef17d3f41",
            "7a0654b6d4c94d7d88abc7a9d384a330",
            "c4f47112ab654f23b18ee21cea505733",
            "0521139088994008867398e2a9732425",
            "79d4f93b3d7949ccbd318dad1dfa0ef8",
            "55b0037ab35847b195d711176e2125e6",
            "fac8c53ea80544359e6d455225f6788c",
            "e669e70319114583b50932b191ce8c3f",
            "5cbf818d5e20415787c58d68313308e0",
            "fe99fed182af4903a7a5651d3be3686a",
            "d720db68cb1c4917830abbdb606c5666",
            "d924a82ffd0f4c729f363aa2a3c4f58d",
            "85bae1fc8bc14aa180af6f6a6d01b38a",
            "70c105a14ae74871a4d7e344ddf08e62",
            "6e6f495f051f4681a5e858d05d07b76f",
            "637cff34386e4d8f992024f5aa1f476e",
            "df9fa9d747a54f609549450dedafeafb",
            "fc7e59a9b4ef4669a0391d37306745cc"
          ]
        },
        "id": "QCOXtmDXvSTD",
        "outputId": "933f1850-01d0-4138-e410-e28e29be8936"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "\n",
        "# Tokenize helper function\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "# Tokenize dataset\n",
        "# Note: here we can use reduced_dataset OR split_dataset\n",
        "if \"label\" in reduced_dataset[\"train\"].features.keys():\n",
        "    reduced_dataset = reduced_dataset.rename_column(\"label\", \"labels\")  # to match Trainer\n",
        "tokenized_dataset = reduced_dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "tokenized_dataset[\"train\"].features.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "269a47991b63467fa0335b7382d8092b",
            "dbee3b95fc474205ba0ba0df4f82b100",
            "d527d912cc8c4565ad1ec2a8ebfceee4",
            "3b0af9b572324b31bad2052546fdc17d",
            "b3ceec40dd2a4488b50aa62bbdbb45fc",
            "3cb67e1e37b64362a6aeeaade0cfd2bd",
            "794edbfce9804c62a7cce936c048fbe1",
            "801246d0c7ac49e0bc3db48e7d0c3d63",
            "41536d221a914d119f32cdb2876367b3",
            "62132a6801c74e2ea64ae28358372fc6",
            "bdc7e54bac234a3dbff7cdb67a976cde",
            "62218afbc50d49828c654438e663d90c",
            "4dabc11d13d7409f9afa30c706842fba",
            "b501e4b4c87640fb94ec2fced53edf82",
            "3fa6346f357b4edcbd6738a85a4572d7",
            "611b97e0f3ca417a853aef09bc640987",
            "058cccf686974d09b805be620fcc18c3",
            "33caccfa3e2f4ab9b1507f40a356575c",
            "38c6e29e675e492a8ca2b7fb79d35740",
            "253430897bc7402a9dbe98ff6be820b0",
            "3aba80954ff0402daf587ca40b4928da",
            "69ef14ea81ca4e5592f637e8a1b71133"
          ]
        },
        "id": "ZtpemiS4JAYy",
        "outputId": "5b64ecf0-af7e-4f4f-8a26-3b4c07a653fd"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "\n",
        "# Save the tokenized dataset to disk\n",
        "tokenized_dataset.save_to_disk('tokenized_dataset_reduced')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFz3B3UiJE4b"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = datasets.load_from_disk('tokenized_dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpfUZf0YEjg3"
      },
      "source": [
        "## Process labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMLotGb17m-B",
        "outputId": "34d6603d-4fc6-47e0-b597-ae1eed58a796"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset.column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcxslXmTvWoY",
        "outputId": "da4ec567-9f66-4d0c-b7fa-51f287283f8a"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Prepare model labels - useful for inference\n",
        "labels = tokenized_dataset[\"train\"].unique(\"labels\")\n",
        "num_labels = len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "a1926da69abd484a9f742121d9b6651e",
            "f3c093e81f7b4e7faedd44345d8d78e1",
            "01a662ffc3d1454781106f82109f4c59",
            "62bef3fd2ecf4351ab269f110678c258",
            "576b9c55eaf94ac9b12b9f199fb55a9f",
            "e53e4d20a263458282c5facd1aaf6c80",
            "54a2d38e19b3492bbdc1fb089f64d000",
            "4c55000769214bd6ae37c860f7a0b6a1",
            "8575f033c812456aab2c8553a6939cbd",
            "9c92d3016fe94be28a36d75de20b4b1a",
            "e26d24d33d024c27b6d411eae773f3f5",
            "ccbb3ca41b2d4718a7aab1714a2d324d",
            "9f99339b1dcc4f05a0afe58bb03e06b4",
            "0f2343b0d4204de0ad26417fdfc093f9",
            "dc35d30a6f59485bb59a779404b6f255",
            "414788145c014791bfdf776a735d91b9",
            "9a135f76a6204c62b500bf99c2294426",
            "a14738eba17b4eb5b3519ef9517575b4",
            "d60596412dee45aa8966bd24a910fe58",
            "3c2b7e2d8caf483095b9cf682e47b3c5",
            "48e0ca64e91d4a93aed8d59d65f6a3e4",
            "4848f35ec2674c27b16f00549f6adc50"
          ]
        },
        "id": "BHGZ1Eh7qrrA",
        "outputId": "f25bfd03-65d4-4461-c82c-e43b5294dd05"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "label2id, id2label = dict(), dict()\n",
        "# for i, label in enumerate(labels):\n",
        "#     label2id[label] = str(i)\n",
        "#     id2label[str(i)] = label\n",
        "\n",
        "label2id['benign'] = 0\n",
        "label2id['malicious'] = 1\n",
        "id2label[0] = 'benign'\n",
        "id2label[1] = 'malicious'\n",
        "\n",
        "# Download the model from huggingface.co/models\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBp7NsoSEm5q"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_niu9MWqvxuu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "# Metric helper method\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    score = f1_score(\n",
        "        labels, predictions, labels=labels, pos_label=1, average=\"weighted\"\n",
        "    )\n",
        "    return {\"f1\": float(score) if score == 1 else score}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUgvFkY7EpOX"
      },
      "source": [
        "## Fine Tuning\n",
        "\n",
        "Fine-tuning means adjusting the weights of a pre-trained model on a new dataset for better performance and specialization in a specific task.\n",
        "\n",
        "<img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52844fcc-6094-4fdb-ba8c-52737ab9c821_1640x402.gif\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"800\"/>\n",
        "\n",
        "(image from [Daily Dose of Data Science](https://blog.dailydoseofds.com/p/full-model-fine-tuning-vs-lora-vs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "Ka4OoZERvz54",
        "outputId": "b921e9e2-365c-459a-8035-b236601b5de5"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# TODO: figure out why loss nan and no improvement in F1\n",
        "import torch\n",
        "from huggingface_hub import HfFolder\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Define training args\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./ModernBERT-domain-classifier\",\n",
        "    per_device_train_batch_size=8,  # Reduced to 8\n",
        "    per_device_eval_batch_size=4,  # Reduced to 4\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=3,\n",
        "    fp16=True,\n",
        "    optim=\"adamw_torch_fused\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    push_to_hub=True,\n",
        "    hub_strategy=\"every_save\",\n",
        "    hub_token=hugging_face_key,\n",
        "    gradient_checkpointing=True,\n",
        "    gradient_accumulation_steps=1, # Reduced to 1\n",
        ")\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K-je3IuErpk"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og7xdhslFRa2",
        "outputId": "82b827f6-b86c-40c0-a4dd-ccf919ebc110"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save_pretrained(\"./fine_tuned_model\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FxzUvcUKQ5rJ",
        "outputId": "e7d15f94-1868-4c94-f280-ca816557a40c"
      },
      "outputs": [],
      "source": [
        "split_dataset[\"test\"][42]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyXXT6gfv4z4",
        "outputId": "a9fe294b-7d3e-4661-ca79-408071181ad5"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from transformers import pipeline\n",
        "\n",
        "# load model from huggingface.co/models using our repository id\n",
        "classifier = pipeline(\n",
        "    task=\"text-classification\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0,\n",
        ")\n",
        "\n",
        "sample = split_dataset[\"test\"][42]['text']\n",
        "\n",
        "# Get the model's configuration\n",
        "config = classifier.model.config\n",
        "\n",
        "# Check if the key 0 exists in id2label, if not, add it with a default label\n",
        "if 0 not in config.id2label:\n",
        "    # Choose a suitable default label\n",
        "    default_label = \"unknown\"\n",
        "    config.id2label[0] = default_label\n",
        "    config.label2id[default_label] = 0\n",
        "\n",
        "classifier(sample)\n",
        "# [{'label': 'health', 'score': 0.6779336333274841}]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
